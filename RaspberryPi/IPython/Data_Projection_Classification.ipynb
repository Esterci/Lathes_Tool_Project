{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_tsfresh ():\n",
    "\n",
    "    #Changing Work Folder\n",
    "    \n",
    "    add_path1 = \"/Input/\"\n",
    "    add_path2 = \"/.Kernel/\"\n",
    "    base_path = os.getcwd()\n",
    "    working_path = os.getcwd()\n",
    "    Input_path = working_path + add_path1\n",
    "    Kernel_path = working_path + add_path2\n",
    "    \n",
    "    # Change folder to Kernel\n",
    "    \n",
    "    os.chdir( Kernel_path )\n",
    "\n",
    "    # Load the the filtered features from the seed data-set\n",
    "\n",
    "    features_filtered = pd.read_csv('features_filtered_3.csv')\n",
    "\n",
    "    # Extract the useful information of it\n",
    "\n",
    "    columns = np.array(features_filtered.columns)\n",
    "    kind_to_fc_parameters = tsfresh.feature_extraction.settings.from_columns(features_filtered.columns)\n",
    "\n",
    "    sensors_names = [None] * int(features_filtered.shape[1]);\n",
    "\n",
    "\n",
    "    for i in range (columns.shape[0]):\n",
    "        name = columns[i]\n",
    "        c = '__';\n",
    "        words = name.split(c)\n",
    "\n",
    "        sensors_names[i] = words[0]\n",
    "\n",
    "        '''if i < 20:\n",
    "\n",
    "            print(name)\n",
    "            print(words)\n",
    "            print(features_names[i])\n",
    "            print(sensors_names[i])\n",
    "            print('_______')'''\n",
    "\n",
    "    columns = columns.tolist()\n",
    "    unique_sensors_names = np.unique(np.array(sensors_names))\n",
    "\n",
    "    # Change folder to Input\n",
    "\n",
    "    os.chdir( Input_path )\n",
    "\n",
    "    # Load the incoming data\n",
    "    \n",
    "    Data = np.genfromtxt('Output_3.csv', delimiter=',')\n",
    "    data_frame = pd.DataFrame(Data[:,0:11], columns= ['id','time'] + ['Sensor_' + str(x) for x in range(1,(Data.shape[1]-2))])\n",
    "\n",
    "    # Feature extraction guided by the seed data-set\n",
    "\n",
    "    extraction_df = pd.DataFrame(data_frame.loc[::,'id':unique_sensors_names[0]].values,columns= ['id','time','Sensor'])\n",
    "    #print(extraction_df.head())\n",
    "    arrayList = [] \n",
    "\n",
    "    for sensor in unique_sensors_names:\n",
    "        \n",
    "        #print(extraction_df.head())\n",
    "        #print('_____')\n",
    "        extraction_df.loc[::,'Sensor'] = data_frame.loc[::,sensor]\n",
    "        \n",
    "        #print(extraction_df.head())\n",
    "        #print('_____')\n",
    "        \n",
    "        extraction_df = extraction_df.rename(columns={'Sensor': sensor})\n",
    "        \n",
    "        tsfresh_parameters = kind_to_fc_parameters[sensor]\n",
    "        \n",
    "        extracted_features = extract_features(extraction_df, column_id=\"id\", column_sort=\"time\", default_fc_parameters=tsfresh_parameters)\n",
    "\n",
    "        arrayList.append(extracted_features)\n",
    "\n",
    "        extraction_df = extraction_df.rename(columns={sensor : 'Sensor'})    \n",
    "\n",
    "    original_space_features = pd.concat(arrayList,axis=1)\n",
    "\n",
    "    # Sort the features in accordance with the seed data-set\n",
    "    \n",
    "    original_space_features = original_space_features[columns]\n",
    "    impute(original_space_features)\n",
    "    original_space_features.sort_index(inplace = True)\n",
    "\n",
    "    # Change folder to origin\n",
    "    \n",
    "    os.chdir( base_path )\n",
    "    \n",
    "    return original_space_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_projection (features):\n",
    "    \n",
    "    #Changing Work Folder\n",
    "        \n",
    "    add_path3 = \"/.Kernel/\"\n",
    "  \n",
    "    base_path = os.getcwd()\n",
    "    working_path = os.getcwd()\n",
    "    Kernel_path = working_path + add_path3\n",
    "        \n",
    "    # Now change to PCA Figures directory\n",
    "\n",
    "    os.chdir( Kernel_path )\n",
    "\n",
    "    # load the model from disk\n",
    "    loaded_pca = pickle.load(open('pca.sav', 'rb'))\n",
    "\n",
    "    scaler = StandardScaler().fit(features)\n",
    "    features_padronizadas = scaler.transform(features)\n",
    "\n",
    "    features_reduzidas = loaded_pca.transform(features_padronizadas)\n",
    "    \n",
    "    #print('Filtered Features')\n",
    "    #print('-' * 20)\n",
    "    #print(np.size(features_padronizadas,0))\n",
    "    #print(np.size(features_padronizadas,1))\n",
    "    #print('-' * 20)\n",
    "    #print('Reduced Features')\n",
    "    #print('-' * 20)\n",
    "    #print(np.size(features_reduzidas,0))\n",
    "    #print(np.size(features_reduzidas,1))\n",
    "    \n",
    "    # Now chance to base directory\n",
    "    \n",
    "    os.chdir( base_path )\n",
    "    \n",
    "    return features_reduzidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Predict (projected_data):\n",
    "    \n",
    "    add_path2 = \"/.Kernel/\";\n",
    "    add_path3 = \"/.Recovery/\";\n",
    "    base_path = os.path.dirname(os.path.abspath(\"Model_Unified_Code.ipynb\"));\n",
    "    Kernel_path = base_path + add_path2;\n",
    "    \n",
    "    # Now change to Kernel directory\n",
    "    \n",
    "    os.chdir( Kernel_path )\n",
    "    \n",
    "    model = pickle.load(open('model.sav', 'rb'))\n",
    "    \n",
    "    for i in range (projected_data.shape[0]):\n",
    "        \n",
    "        y_predict = model.predict(projected_data[i,:].reshape(1, -1))\n",
    "    \n",
    "        if y_predict[0] == 0:\n",
    "            print('Ferramenta Boa')\n",
    "        else:\n",
    "            print('Ferramenta Ruim')\n",
    "    \n",
    "        #print ('Label de Teste: %d' % int (projected_data[i]))\n",
    "        print ('Label dado pale NN: %d' % int (y_predict[0]))\n",
    "        print('___________________')\n",
    "        print('                   ')\n",
    "        \n",
    "    # Now change to the base directory\n",
    "    \n",
    "    os.chdir( base_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tsfresh \n",
    "from tsfresh import extract_features\n",
    "import pickle\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/thiago/Repositories/Lathes_Tool_Project/RaspberryPi/IPython/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [00:03<00:00,  2.71it/s]\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:02<00:00,  3.37it/s]\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:02<00:00,  4.64it/s]\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:02<00:00,  4.40it/s]\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:02<00:00,  4.39it/s]\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:02<00:00,  4.34it/s]\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:02<00:00,  3.36it/s]\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:02<00:00,  4.14it/s]\n",
      "Feature Extraction: 100%|██████████| 10/10 [00:02<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Ruim\n",
      "Label dado pale NN: 1\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n",
      "Ferramenta Boa\n",
      "Label dado pale NN: 0\n",
      "___________________\n",
      "                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago/anaconda3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator PCA from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/thiago/anaconda3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/thiago/anaconda3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.23.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "features = dynamic_tsfresh()\n",
    "\n",
    "projected_data = PCA_projection(features)\n",
    "\n",
    "Model_Predict(projected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 3. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 3.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 3. 3. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 3. 3. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2.\n",
      " 2. 2. 3. 3. 3. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 1. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "os.chdir('/home/thiago/Repositories/Lathes_Tool_Project/RaspberryPi/IPython/Input/')\n",
    "\n",
    "i = 0;\n",
    "\n",
    "all_files = glob.glob('/home/thiago/Repositories/Lathes_Tool_Project/RaspberryPi/IPython/.Kernel/*.csv') #give path to your desired file path\n",
    "latest_csv = max(all_files, key=os.path.getctime)\n",
    "data = np.genfromtxt(latest_csv,delimiter=',')  \n",
    "print (data)\n",
    "\n",
    "os.chdir('/home/thiago/Repositories/Lathes_Tool_Project/RaspberryPi/IPython/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
